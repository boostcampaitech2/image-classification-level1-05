{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "source": [
    "# System Libs\n",
    "import multiprocessing as mp\n",
    "import sys\n",
    "import os\n",
    "import argparse\n",
    "import json\n",
    "from importlib import import_module\n",
    "from pathlib import Path\n",
    "from glob import glob\n",
    "from time import time\n",
    "\n",
    "# Other Libs\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import cv2\n",
    "from sklearn.metrics import f1_score\n",
    "from PIL import Image\n",
    "from tqdm import tqdm\n",
    "from sklearn.metrics import f1_score\n",
    "\n",
    "# Torch\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch import optim\n",
    "from torch.optim.lr_scheduler import StepLR\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "from torchvision import models\n",
    "from torchvision import transforms\n",
    "from torchvision.transforms import CenterCrop, Resize, ToTensor, Normalize\n",
    "device = (\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(device)\n",
    "\n",
    "# Local Libs\n",
    "from dataset import TrainInfo, MaskBaseDataset, TestDataset\n",
    "from model import BaseModel, ResNet18Pretrained\n",
    "from loss import get_criterion\n",
    "import settings\n",
    "import logger"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "cuda\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "source": [
    "import argparse\n",
    "import os\n",
    "from importlib import import_module\n",
    "\n",
    "import pandas as pd\n",
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "from dataset import MaskBaseDataset, TestDataset"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "source": [
    "def load_model(model_dir, device):\n",
    "    # model_path = os.path.join(model_dir, args.model_name)\n",
    "    model = torch.load(model_dir, map_location=device)\n",
    "\n",
    "    return model "
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "source": [
    "    parser = argparse.ArgumentParser()\n",
    "\n",
    "    # Container environment\n",
    "    parser.add_argument('--data_dir', type=str, default=os.environ.get('SM_CHANNEL_EVAL', '/opt/ml/input/data/eval'))\n",
    "    parser.add_argument('--new_dataset', type=bool, default=False)\n",
    "    parser.add_argument('--model_dir', type=str, default=os.environ.get('SM_CHANNEL_MODEL', './model'))\n",
    "    parser.add_argument('--name', type=str, default='exp')\n",
    "    parser.add_argument('--output_dir', type=str, default=os.environ.get('SM_OUTPUT_DATA_DIR', './output'))\n",
    "    parser.add_argument('--model_name', type=str, default='best.pt')\n",
    "\n",
    "    parser.add_argument('--batch_size', type=int, default=1000, help='input batch size for validing (default: 1000)')\n",
    "    parser.add_argument('--resize', type=tuple, default=(512, 384), help='resize size for image when you trained (default: (512, 384))')\n",
    "    parser.add_argument('--mode', type=str, default='all', help='choose all or ensemble')\n",
    "    args = parser.parse_args([])\n",
    "\n",
    "    os.makedirs(args.output_dir, exist_ok=True)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "source": [
    "# Settings\n",
    "data_dir = args.data_dir\n",
    "output_dir = args.output_dir\n",
    "\n",
    "is_cuda = torch.cuda.is_available()\n",
    "device = torch.device(\"cuda\" if is_cuda else \"cpu\")\n",
    "\n",
    "# Models\n",
    "model_dir = '/opt/ml/image-classification-level1-05/model'\n",
    "\n",
    "######################### ADD ##########################\n",
    "model_mask_jw = Path(model_dir).joinpath('mask_jw.pt')\n",
    "model_gender_jw = Path(model_dir).joinpath('gender_jw.pt')\n",
    "model_age_jw = Path(model_dir).joinpath('age_jw.pt')\n",
    "\n",
    "model_mask_jw = load_model(model_mask_jw, device).to(device)\n",
    "model_gender_jw = load_model(model_gender_jw, device).to(device)\n",
    "model_age_jw = load_model(model_age_jw, device).to(device)\n",
    "\n",
    "model_mask_jw.eval()\n",
    "model_gender_jw.eval()\n",
    "model_age_jw.eval()\n",
    "########################################################\n",
    "\n",
    "model_mask = Path(model_dir).joinpath('model_mask/model_mask_f1.pt')\n",
    "model_mask_age = Path(model_dir).joinpath('model_mask_age/model_mask_age_f1.pt')\n",
    "model_mask_gender = Path(model_dir).joinpath('model_mask_gender/model_mask_gender_f1.pt')\n",
    "model_nomask_age = Path(model_dir).joinpath('model_nomask_age/model_nomask_age_f1.pt')\n",
    "model_nomask_gender = Path(model_dir).joinpath('model_nomask_gender/model_nomask_gender_f1.pt')\n",
    "\n",
    "model_mask = load_model(model_mask, device).to(device)\n",
    "model_mask_age = load_model(model_mask_age, device).to(device)\n",
    "model_mask_gender = load_model(model_mask_gender, device).to(device)\n",
    "model_nomask_age = load_model(model_nomask_age, device).to(device)\n",
    "model_nomask_gender = load_model(model_nomask_gender, device).to(device)\n",
    "\n",
    "model_mask.eval()\n",
    "model_mask_age.eval()\n",
    "model_mask_gender.eval()\n",
    "model_nomask_age.eval()\n",
    "model_nomask_gender.eval()\n",
    "\n",
    "# Image Files & DataLoader\n",
    "img_root = os.path.join(data_dir, 'images')\n",
    "info_path = os.path.join(data_dir, 'info.csv')\n",
    "info = pd.read_csv(info_path)\n",
    "\n",
    "img_paths = [os.path.join(img_root, img_id) for img_id in info.ImageID]\n",
    "dataset = TestDataset(img_paths, args.resize)\n",
    "loader = torch.utils.data.DataLoader(\n",
    "    dataset,\n",
    "    batch_size=1,\n",
    "    num_workers=2,\n",
    "    shuffle=False,\n",
    "    pin_memory=is_cuda,\n",
    "    drop_last=False,\n",
    ")"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "source": [
    "print(\"Calculating inference results..\")\n",
    "preds = []\n",
    "with torch.no_grad():\n",
    "    for images in tqdm(loader):\n",
    "\n",
    "        images = images.to(device)\n",
    "\n",
    "        # 마스크 예측 - 0: Wear, 1: Incorrect, 2: Not Wear\n",
    "        pred = model_mask_jw(images)\n",
    "        pred_mask = pred.argmax(dim=-1)\n",
    "        \n",
    "        pred = model_gender_jw(images)\n",
    "        pred_gender = pred.argmax(dim=-1)\n",
    "\n",
    "        pred = model_age_jw(images)\n",
    "        pred_age = pred.argmax(dim=-1)\n",
    "\n",
    "        # 마스크 착용 케이스 - 광현\n",
    "        if int(pred_mask) != 2:\n",
    "            if int(pred_age) == 1:\n",
    "                pred = model_mask_age(images)\n",
    "                cand = pred.argmax(dim=-1)\n",
    "                pred_age = cand if pred_age == 2 else pred_age\n",
    "\n",
    "            # pred = model_nomask_gender(images)\n",
    "            # pred_gender = pred.argmax(dim=-1)\n",
    "\n",
    "        # 마스크 착용 케이스\n",
    "        # else:   \n",
    "        #     pred = model_mask_age(images)\n",
    "        #     pred_age_cond = pred.argmax(dim=-1)\n",
    "\n",
    "            # pred = model_mask_gender(images)\n",
    "            # pred_gender = pred.argmax(dim=-1)    \n",
    "        \n",
    "\n",
    "        result = pred_mask * 6 + pred_gender * 3 + pred_age\n",
    "        preds.extend(result.cpu().numpy())\n",
    "\n",
    "\n",
    "\n",
    "    info['ans'] = preds\n",
    "    info.to_csv(os.path.join(output_dir, f'{args.name}_output.csv'), index=False)\n",
    "    print(f'Inference Done!')"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Calculating inference results..\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "100%|██████████| 12600/12600 [01:46<00:00, 118.28it/s]"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Inference Done!\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "<br><br><br>"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 분포 확인\n",
    "---"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "source": [
    "ans_list = info.ans.unique()\n",
    "ans_list.sort()\n",
    "\n",
    "print(f'length : {len(ans_list)} | {ans_list}')"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "length : 18 | [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17]\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [],
   "outputs": [],
   "metadata": {}
  }
 ],
 "metadata": {
  "orig_nbformat": 4,
  "language_info": {
   "name": "python",
   "version": "3.8.5",
   "mimetype": "text/x-python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "pygments_lexer": "ipython3",
   "nbconvert_exporter": "python",
   "file_extension": ".py"
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.8.5 64-bit ('base': conda)"
  },
  "interpreter": {
   "hash": "98b0a9b7b4eaaa670588a142fd0a9b87eaafe866f1db4228be72b4211d12040f"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}