{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "source": [
    "# System Libs\n",
    "import multiprocessing as mp\n",
    "import sys\n",
    "import os\n",
    "from glob import glob\n",
    "from time import time\n",
    "from pathlib import Path\n",
    "\n",
    "# Other Libs\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import cv2\n",
    "from sklearn.metrics import f1_score\n",
    "from PIL import Image\n",
    "from tqdm import tqdm\n",
    "\n",
    "# Torch\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch import optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision import transforms\n",
    "from torchvision.transforms import CenterCrop, Resize, ToTensor, Normalize\n",
    "device = (\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(device)\n",
    "\n",
    "# Local Libs\n",
    "from data_utils import MaskClassifierDataset\n",
    "from models import BaseModel"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "cuda\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "source": [
    "# Path Setting\n",
    "# Project Dir\n",
    "dir_project = Path('/opt/ml')\n",
    "\n",
    "# Code Dir\n",
    "dir_code = dir_project.joinpath('code')\n",
    "\n",
    "# Model Dir\n",
    "dir_model = dir_project.joinpath('model')\n",
    "\n",
    "# Code Data\n",
    "dir_data = dir_project.joinpath('input/data')\n",
    "dir_eval = dir_data.joinpath('eval')\n",
    "dir_train = dir_data.joinpath('train')\n",
    "\n",
    "# Train Data\n",
    "dir_img = dir_train.joinpath('images')\n",
    "file_train_raw = dir_train.joinpath('train.csv')\n",
    "file_train = dir_train.joinpath('train_processed.csv')"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "source": [
    "# 테스트 데이터셋 폴더 경로를 지정해주세요.\n",
    "test_dir = '/opt/ml/input/data/eval'"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "<br><br><br>\n",
    "# 1. Dataset & DataLoader\n",
    "---"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "source": [
    "class TestDataset(Dataset):\n",
    "    def __init__(self, img_paths, transform):\n",
    "        self.img_paths = img_paths\n",
    "        self.transform = transform\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        image = Image.open(self.img_paths[index])\n",
    "\n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "        return image\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.img_paths)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "<br><br><br>\n",
    "# 2. Model\n",
    "---"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "source": [
    "model = BaseModel(num_classes=18)\n",
    "model.load_state_dict(torch.load(dir_model.joinpath('model_base.pt')))\n",
    "model.to(device)\n",
    "model.eval()"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "BaseModel(\n",
       "  (features): Sequential(\n",
       "    (0): Conv2d(3, 64, kernel_size=(11, 11), stride=(4, 4), padding=(2, 2))\n",
       "    (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU(inplace=True)\n",
       "  )\n",
       "  (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
       "  (classifier): Sequential(\n",
       "    (0): Dropout(p=0.5, inplace=False)\n",
       "    (1): Linear(in_features=64, out_features=32, bias=True)\n",
       "    (2): ReLU(inplace=True)\n",
       "    (3): Linear(in_features=32, out_features=18, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "metadata": {},
     "execution_count": 6
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "<br><br><br>\n",
    "# 3. Inference\n",
    "---"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "source": [
    "# meta 데이터와 이미지 경로를 불러옵니다.\n",
    "submission = pd.read_csv(os.path.join(test_dir, 'info.csv'))\n",
    "image_dir = os.path.join(test_dir, 'images')\n",
    "\n",
    "# Test Dataset 클래스 객체를 생성하고 DataLoader를 만듭니다.\n",
    "image_paths = [os.path.join(image_dir, img_id) for img_id in submission.ImageID]\n",
    "transform = transforms.Compose(\n",
    "        [\n",
    "            transforms.ToTensor(),\n",
    "        ]\n",
    "    )\n",
    "dataset = TestDataset(image_paths, transform)\n",
    "loader = DataLoader(\n",
    "    dataset,\n",
    "    shuffle=False\n",
    ")\n",
    "\n",
    "# 모델을 정의합니다. (학습한 모델이 있다면 torch.load로 모델을 불러주세요!)\n",
    "# device = torch.device('cuda')\n",
    "# model = MyModel(num_classes=18).to(device)\n",
    "# model.eval()\n",
    "# model = torch.load(dir_model.joinpath('model_01.pt'))\n",
    "# print(model.eval())"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "source": [
    "# 모델이 테스트 데이터셋을 예측하고 결과를 저장합니다.\n",
    "all_predictions = []\n",
    "for images in loader:\n",
    "    with torch.no_grad():\n",
    "        images = images.to(device)\n",
    "        pred = model(images)\n",
    "        pred = pred.argmax(dim=-1)\n",
    "        all_predictions.extend(pred.cpu().numpy())\n",
    "submission['ans'] = all_predictions\n",
    "\n",
    "# 제출할 파일을 저장합니다.\n",
    "submission.to_csv(os.path.join(test_dir, 'submission.csv'), index=False)\n",
    "print('test inference is done!')"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "test inference is done!\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "source": [
    "submission.to_csv(os.path.join(test_dir, 'submission.csv'), index=False)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "source": [],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "tensor([[[0.7569, 0.8275, 0.7373,  ..., 0.2157, 0.1961, 0.1725],\n",
       "         [0.5020, 0.4471, 0.3608,  ..., 0.1961, 0.1843, 0.1686],\n",
       "         [0.3412, 0.2549, 0.3176,  ..., 0.1765, 0.1765, 0.1725],\n",
       "         ...,\n",
       "         [0.0902, 0.0902, 0.0902,  ..., 0.1451, 0.1451, 0.1686],\n",
       "         [0.0902, 0.0902, 0.0941,  ..., 0.1412, 0.1216, 0.1333],\n",
       "         [0.1020, 0.1020, 0.1059,  ..., 0.1294, 0.0824, 0.0902]],\n",
       "\n",
       "        [[0.7882, 0.8588, 0.7725,  ..., 0.2235, 0.2039, 0.1804],\n",
       "         [0.5333, 0.4784, 0.3961,  ..., 0.2039, 0.1922, 0.1765],\n",
       "         [0.3725, 0.2863, 0.3529,  ..., 0.1843, 0.1843, 0.1804],\n",
       "         ...,\n",
       "         [0.1059, 0.1059, 0.1059,  ..., 0.1608, 0.1608, 0.1843],\n",
       "         [0.1059, 0.1059, 0.1098,  ..., 0.1569, 0.1373, 0.1490],\n",
       "         [0.1176, 0.1176, 0.1216,  ..., 0.1451, 0.0980, 0.1059]],\n",
       "\n",
       "        [[0.7961, 0.8667, 0.7686,  ..., 0.1804, 0.1608, 0.1373],\n",
       "         [0.5412, 0.4863, 0.3922,  ..., 0.1608, 0.1490, 0.1333],\n",
       "         [0.3804, 0.2941, 0.3490,  ..., 0.1412, 0.1412, 0.1373],\n",
       "         ...,\n",
       "         [0.1412, 0.1412, 0.1412,  ..., 0.2078, 0.2078, 0.2314],\n",
       "         [0.1412, 0.1412, 0.1451,  ..., 0.2039, 0.1843, 0.1961],\n",
       "         [0.1529, 0.1529, 0.1569,  ..., 0.1922, 0.1451, 0.1529]]])"
      ]
     },
     "metadata": {},
     "execution_count": 13
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "source": [
    "l = iter(loader)\n",
    "data = l.next()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "source": [
    "with torch.no_grad():\n",
    "    data = data.to(device)\n",
    "    pred = model(images)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "source": [
    "pred"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "tensor([[ 99584.9141, 100431.1641,  99776.9453,  99888.3281,  99624.9062,\n",
       "         100044.6484,  99001.0469, 100536.5859,  99900.8516,  99356.3516,\n",
       "          99655.2500,  99974.5625,  99492.0312, 100490.0234, 100170.6484,\n",
       "         100375.2812,  99304.6797,  99252.2031]], device='cuda:0')"
      ]
     },
     "metadata": {},
     "execution_count": 22
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [],
   "outputs": [],
   "metadata": {}
  }
 ],
 "metadata": {
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.8.5 64-bit ('base': conda)"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "interpreter": {
   "hash": "98b0a9b7b4eaaa670588a142fd0a9b87eaafe866f1db4228be72b4211d12040f"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}