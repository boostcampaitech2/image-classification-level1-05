{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 22,
   "source": [
    "# System Libs\n",
    "import multiprocessing as mp\n",
    "import sys\n",
    "import os\n",
    "from glob import glob\n",
    "from time import time\n",
    "from pathlib import Path\n",
    "\n",
    "# Other Libs\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import cv2\n",
    "from sklearn.metrics import f1_score\n",
    "from PIL import Image\n",
    "from tqdm import tqdm\n",
    "\n",
    "# Torch\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch import optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision import transforms\n",
    "from torchvision.transforms import CenterCrop, Resize, ToTensor, Normalize\n",
    "device = (\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(device)\n",
    "\n",
    "# Local Libs\n",
    "from data_utils import MaskClassifierDataset\n",
    "from models import BaseModel"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "cuda\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "source": [
    "# Path Setting\n",
    "# Project Dir\n",
    "dir_project = Path('/opt/ml')\n",
    "\n",
    "# Code Dir\n",
    "dir_code = dir_project.joinpath('code')\n",
    "\n",
    "# Model Dir\n",
    "dir_model = dir_project.joinpath('model')\n",
    "\n",
    "# Code Data\n",
    "dir_data = dir_project.joinpath('input/data')\n",
    "dir_eval = dir_data.joinpath('eval')\n",
    "dir_train = dir_data.joinpath('train')\n",
    "\n",
    "# Train Data\n",
    "dir_img = dir_train.joinpath('images')\n",
    "file_train_raw = dir_train.joinpath('train.csv')\n",
    "file_train = dir_train.joinpath('train_processed.csv')"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "source": [
    "# train_processed.csv \n",
    "train_df = pd.read_csv(file_train, index_col=0)\n",
    "train_df.head(5)"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "       id                                               path  Mask  \\\n",
       "0  000001  /opt/ml/input/data/train/images/000001_female_...  Wear   \n",
       "1  000001  /opt/ml/input/data/train/images/000001_female_...  Wear   \n",
       "2  000001  /opt/ml/input/data/train/images/000001_female_...  Wear   \n",
       "3  000001  /opt/ml/input/data/train/images/000001_female_...  Wear   \n",
       "4  000001  /opt/ml/input/data/train/images/000001_female_...  Wear   \n",
       "\n",
       "              Age  Gender  Class  \n",
       "0  >= 30 and < 60  Female      4  \n",
       "1  >= 30 and < 60  Female      4  \n",
       "2  >= 30 and < 60  Female      4  \n",
       "3  >= 30 and < 60  Female      4  \n",
       "4  >= 30 and < 60  Female      4  "
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>path</th>\n",
       "      <th>Mask</th>\n",
       "      <th>Age</th>\n",
       "      <th>Gender</th>\n",
       "      <th>Class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>000001</td>\n",
       "      <td>/opt/ml/input/data/train/images/000001_female_...</td>\n",
       "      <td>Wear</td>\n",
       "      <td>&gt;= 30 and &lt; 60</td>\n",
       "      <td>Female</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>000001</td>\n",
       "      <td>/opt/ml/input/data/train/images/000001_female_...</td>\n",
       "      <td>Wear</td>\n",
       "      <td>&gt;= 30 and &lt; 60</td>\n",
       "      <td>Female</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>000001</td>\n",
       "      <td>/opt/ml/input/data/train/images/000001_female_...</td>\n",
       "      <td>Wear</td>\n",
       "      <td>&gt;= 30 and &lt; 60</td>\n",
       "      <td>Female</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>000001</td>\n",
       "      <td>/opt/ml/input/data/train/images/000001_female_...</td>\n",
       "      <td>Wear</td>\n",
       "      <td>&gt;= 30 and &lt; 60</td>\n",
       "      <td>Female</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>000001</td>\n",
       "      <td>/opt/ml/input/data/train/images/000001_female_...</td>\n",
       "      <td>Wear</td>\n",
       "      <td>&gt;= 30 and &lt; 60</td>\n",
       "      <td>Female</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ]
     },
     "metadata": {},
     "execution_count": 24
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "<br><br><br>\n",
    "## 1. Dataset & DataLoader\n",
    "---"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "source": [
    "preprocess = transforms.Compose(\n",
    "    [\n",
    "        transforms.ToTensor()\n",
    "    ]\n",
    ")\n",
    "\n",
    "dataset = MaskClassifierDataset(train_df, transform=preprocess)\n",
    "loader = DataLoader(dataset, shuffle=True, batch_size=10)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "<br><br><br>\n",
    "## 2. Model\n",
    "---"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "source": [
    "# model = BaseModel(num_classes=18)\n",
    "# model.to(device)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "source": [
    "def resnet_finetune(model, classes):\n",
    "\tmodel = model()\n",
    "\t# class 18개로 분리\n",
    "\tmodel.fc = nn.Linear(in_features=512, out_features=classes, bias=True)\n",
    "\t\n",
    "\tprint(\"네트워크 필요 입력 채널 개수\", model.conv1.weight.shape[1])\n",
    "\tprint(\"네트워크 출력 채널 개수 (예측 class type 개수)\", model.fc.weight.shape[0])\n",
    "\n",
    "\treturn model"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "source": [
    "from torchvision.models import resnet18\n",
    "\n",
    "model = resnet_finetune(resnet18, 18).to(device)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "네트워크 필요 입력 채널 개수 3\n",
      "네트워크 출력 채널 개수 (예측 class type 개수) 18\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "<br><br><br>\n",
    "## 3. Inference\n",
    "---"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "source": [
    "# Hyper-parameter\n",
    "learning_rate = 1e-4\n",
    "epochs = 3"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "source": [
    "criterion = nn.MultiLabelSoftMarginLoss().to(device)\n",
    "optimizer = optim.Adam(params=model.parameters(), lr=learning_rate)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "source": [
    "for epoch in range(1, epochs+1):\n",
    "    running_loss = 0.\n",
    "    running_acc = 0.\n",
    "\n",
    "    for idx, (images, labels) in enumerate(tqdm(loader)):\n",
    "        images = torch.stack(list(images), dim=0).to(device)\n",
    "        labels = torch.tensor(list(labels)).to(device)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        with torch.set_grad_enabled(True):\n",
    "            logits = model(images)\n",
    "            _, preds = torch.max(logits, 1)\n",
    "            loss = criterion(logits, labels)\n",
    "\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "        running_loss += loss.item()*images.size(0)\n",
    "        running_acc += torch.sum(preds == labels.data)\n",
    "\n",
    "    epoch_loss = running_loss / len(loader.dataset)\n",
    "    epoch_acc = running_acc / len(loader.dataset)\n",
    "\n",
    "    print(f\"현재 epoch-{epoch}의 데이터 셋에서 평균 Loss : {epoch_loss:.3f}, 평균 Accuracy : {epoch_acc:.3f}\")\n",
    "print(\"학습 종료!\")"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "100%|██████████| 18900/18900 [05:41<00:00, 55.31it/s]\n"
     ]
    },
    {
     "output_type": "error",
     "ename": "NameError",
     "evalue": "name 'phase' is not defined",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-20-712159a1d0d1>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     23\u001b[0m     \u001b[0mepoch_acc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrunning_acc\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloader\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 25\u001b[0;31m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"현재 epoch-{epoch}의 {phase}-데이터 셋에서 평균 Loss : {epoch_loss:.3f}, 평균 Accuracy : {epoch_acc:.3f}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     26\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"학습 종료!\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'phase' is not defined"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "source": [
    "    print(f\"현재 epoch-{epoch}의 데이터 셋에서 평균 Loss : {epoch_loss:.3f}, 평균 Accuracy : {epoch_acc:.3f}\")\n"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "현재 epoch-1의 데이터 셋에서 평균 Loss : 0.225, 평균 Accuracy : 0.004\n"
     ]
    }
   ],
   "metadata": {}
  }
 ],
 "metadata": {
  "orig_nbformat": 4,
  "language_info": {
   "name": "python",
   "version": "3.8.5",
   "mimetype": "text/x-python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "pygments_lexer": "ipython3",
   "nbconvert_exporter": "python",
   "file_extension": ".py"
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.8.5 64-bit ('base': conda)"
  },
  "interpreter": {
   "hash": "98b0a9b7b4eaaa670588a142fd0a9b87eaafe866f1db4228be72b4211d12040f"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}